{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8e8044-6702-4b90-bf41-5964225b5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545828e5-8b55-464f-bf77-5d8ecbd26a27",
   "metadata": {},
   "source": [
    "### Lista de arquivos para leitura\n",
    "\n",
    "Criando uma lista com os arquivos CSV baixados no DataSAS utilizando o módulo os.\n",
    "\n",
    "**link para baixar arquivos:** https://sistemas.anac.gov.br/sas/downloads/view/frmDownload.aspx  \n",
    "**Tema:** \"Tarifas Transporte Aéreo Passageiros Domésticos\"\n",
    "\n",
    "Usei o os.listdir para que retorne uma lista contendo os nomes das entradas no diretório passado como caminho. O objetivo disso é possibilitar a a concatenação através da abertura por nome dos arquivos.\n",
    "\n",
    "Mas como podem ter arquivos diferentes dos CSV que é o que interessa, utilizei um *for* com um *if* e o método *'endwith'* para buscar apenas os arquivos terminados em *'.CSV'*.\n",
    "\n",
    "Posteriomente adicionei esses arquivos numa lista chamada *'dir_list'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b8582c-bccb-449c-a6d2-a70af01595a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201801.CSV', '201802.CSV', '201803.CSV', '201804.CSV', '201805.CSV', '201806.CSV', '201807.CSV', '201808.CSV', '201809.CSV', '201810.CSV', '201811.CSV', '201812.CSV', '201901.CSV', '201902.CSV', '201903.CSV', '201904.CSV', '201905.CSV', '201906.CSV', '201907.CSV', '201908.CSV', '201909.CSV', '201910.CSV', '201911.CSV', '201912.CSV', '202001.CSV', '202002.CSV', '202003.CSV', '202004.CSV', '202005.CSV', '202006.CSV', '202007.CSV', '202008.CSV', '202009.CSV', '202010.CSV', '202011.CSV', '202012.CSV', '202101.CSV', '202102.CSV', '202103.CSV', '202104.CSV', '202105.CSV', '202106.CSV', '202107.CSV', '202108.CSV', '202109.CSV', '202110.CSV', '202111.CSV', '202112.CSV', '202201.CSV', '202202.CSV', '202203.CSV', '202204.CSV', '202205.CSV', '202206.CSV', '202207.CSV', '202208.CSV']\n"
     ]
    }
   ],
   "source": [
    "dir_list = []\n",
    "for l in os.listdir(\"C:\\workspace\\dash-voos-sbrf\\datasets\"):\n",
    "    if l.endswith(\".CSV\"):\n",
    "        dir_list.append(l)\n",
    "print(dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f2750-ab22-4158-8c24-41165e1c84ec",
   "metadata": {},
   "source": [
    "### Criando dum DataFrame\n",
    "\n",
    "Agora criei um DataFrame vazio passando apenas os nomes das colunas para posteriormente recebera concatenação dos arquivos que são mensais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e95f1e9-9964-4d80-a43f-bfd5ae10dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbrf = pd.DataFrame(columns=['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720e9ab-7bda-4be8-847d-bf4b0dbcb554",
   "metadata": {},
   "source": [
    "### Concatenando os arquivos\n",
    "\n",
    "Criei um *for* para concatenar os arquivos mensais no DataFrame *'df_sbrf'* criado para receber os vôos com origem no aeroporto do Recife(SBRF).\n",
    "\n",
    "Para isso criei:\n",
    "- Um DataFrame temporario(*df_temp*);\n",
    "- Usei o *'.loc'* para buscar na coluna 'ORIGEM' linhas com o conteúdo 'SBRF'; \n",
    "- Então usei o *'pd.concat'* para concatenar o conteúdo filtrado pelo *'.loc'* ao DataFrame *'df_sbrf'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c476ca0-f384-4fd0-aa45-10e8e3c9aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    df_temp = pd.read_csv(dir_list[c], sep=';')\n",
    "    df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "    df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48468a53-de9e-4992-94cb-f51bc6dadf6a",
   "metadata": {},
   "source": [
    "### UnicodeDecodeError\n",
    "\n",
    "Ao rodar o código retornou o erro: **UnicodeDecodeError: 'utf-8' codec can't decode byte 0xea in position 12: invalid continuation byte**\n",
    "\n",
    "O erro foi causado possivelmente pelo Python estar pegando o enconding local da máquina e este não ser utf-8.\n",
    "\n",
    "A solução é declarar o enconding diretamente na codificação da seguinte forma:  \n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='utf-8', sep=';')\n",
    "\n",
    "Porém a solução com o encoding *encoding='utf-8'* não resolveu o problema, então substituí pelo *encoding='ISO-8859-1'*. Daí este funcionou.\n",
    "\n",
    "Na prática isto aconteceu porque alguns arquivos tinha cabeçalhos diferentes utilizando acentuações, detalhe que só percebi mais a frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621025e-6849-4d7f-ac98-d1c936810b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "    df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "    df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d4c64-06a5-4c4d-a5a6-87948e5932a2",
   "metadata": {},
   "source": [
    "### AttributeError\n",
    "\n",
    "Ao rodar o código novamente ele aprensentou um novo erro: **AttributeError: 'DataFrame' object has no attribute 'ORIGEM'**\n",
    "\n",
    "Então utilizei um *'try'* para testar os arquivos que estavam retornando este erro, com o *'except'* usando o *print* para mostrar estes arquivos na .\n",
    "\n",
    "Ao verificá-los abrindo os primeiros deles com o bloco de notas percebi que eles apresentavam o cabeçalho diferente do que eu tinha verificado anteriormente, por isso não encontravam a coluna 'ORIGEM' e por causa destas colunas vinha dando o *UnicodeDecodeError*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "781ad41a-ae64-454d-aec3-8c902c5c8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erro no arquivo: 201802.CSV\n",
      "erro no arquivo: 201803.CSV\n",
      "erro no arquivo: 201804.CSV\n",
      "erro no arquivo: 201805.CSV\n",
      "erro no arquivo: 201806.CSV\n",
      "erro no arquivo: 201807.CSV\n",
      "erro no arquivo: 201808.CSV\n",
      "erro no arquivo: 201810.CSV\n",
      "erro no arquivo: 201811.CSV\n",
      "erro no arquivo: 201812.CSV\n",
      "erro no arquivo: 201903.CSV\n",
      "erro no arquivo: 201912.CSV\n",
      "erro no arquivo: 202001.CSV\n",
      "erro no arquivo: 202002.CSV\n",
      "erro no arquivo: 202003.CSV\n",
      "erro no arquivo: 202005.CSV\n",
      "erro no arquivo: 202006.CSV\n",
      "erro no arquivo: 202007.CSV\n",
      "erro no arquivo: 202008.CSV\n",
      "erro no arquivo: 202009.CSV\n",
      "erro no arquivo: 202010.CSV\n",
      "erro no arquivo: 202011.CSV\n",
      "erro no arquivo: 202012.CSV\n",
      "erro no arquivo: 202102.CSV\n",
      "erro no arquivo: 202103.CSV\n",
      "erro no arquivo: 202104.CSV\n",
      "erro no arquivo: 202106.CSV\n",
      "erro no arquivo: 202107.CSV\n",
      "erro no arquivo: 202108.CSV\n",
      "erro no arquivo: 202112.CSV\n",
      "erro no arquivo: 202201.CSV\n",
      "erro no arquivo: 202202.CSV\n",
      "erro no arquivo: 202203.CSV\n",
      "erro no arquivo: 202204.CSV\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        print(f'erro no arquivo: {dir_list[c]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b1002-ec79-4e94-8d01-3eb944c9bd0c",
   "metadata": {},
   "source": [
    "### Solução testada\n",
    "\n",
    "A solução que tentei foi usar *df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']* para alterar os nomes das colunas e torná-las iguais as demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c916f-0a79-4161-96ce-1716960ac647",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "    df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "    df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "    df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389b6a4-d9c5-40e6-a55e-f2abc14685a0",
   "metadata": {},
   "source": [
    "### ValueError\n",
    "\n",
    "Ao rodar o código ele aprensentou um novo erro: **ValueError: Length mismatch: Expected axis has 8 elements, new values have 7 elements**\n",
    "\n",
    "Utilizei novamento o *'try'* e o *'except'* para mostrar os arquivos com problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1498494b-479b-483b-8847-8935a4913b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erro no arquivo: 202112.CSV\n",
      "erro no arquivo: 202204.CSV\n"
     ]
    }
   ],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)\n",
    "    except:\n",
    "        print(f'erro no arquivo: {dir_list[c]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abcf6e0-d352-4b19-aa8b-ced1adef72b0",
   "metadata": {},
   "source": [
    "### Solução testada:\n",
    "\n",
    "Ao abrir os dois arquivos com problemas notei que eles apresentavam uma primeira coluna com índice, diferente dos demais que não vinham com esta coluna.\n",
    "\n",
    "Como a coluna *'índice'* não era nomeada testei utilizar uma linha de código *df_temp.drop(\"\", axis=1, inplace=True)* para remover a primeira coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499a878-4164-42b0-ba82-a3d6e0ca3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)\n",
    "    except ValueError:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp.drop(\"\", axis=1, inplace=True)\n",
    "        df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db28ae6-6f79-4683-b1ed-584609d11667",
   "metadata": {},
   "source": [
    "### KeyError\n",
    "\n",
    "Ao rodar o código ele aprensentou mais um novo erro: **KeyError: \"[''] not found in axis\"**\n",
    "\n",
    "Ele apresentou este erro pois não consegui encontrar uma coluna com o nome ''. A solução que criei foi renomear a colunar para posteriormente excluí-la.\n",
    "\n",
    "Então utilizei o método *df_temp.columns.values[0] = 'excluir'* para renomear a coluna de nome vazio para *excluir* e depois utilizei a *df_temp.drop('excluir', axis=1, inplace=True)* novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e9212030-ba10-4232-ba80-e28772bf705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(dir_list)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)\n",
    "    except ValueError:\n",
    "        df_temp = pd.read_csv(dir_list[c], encoding='ISO-8859-1', sep=';')\n",
    "        df_temp.columns.values[0] = 'excluir'\n",
    "        df_temp.drop('excluir', axis=1, inplace=True)\n",
    "        df_temp.columns = ['ANO','MES','EMPRESA','ORIGEM','DESTINO','TARIFA','ASSENTOS']\n",
    "        df_temp = df_temp.loc[(df_temp.ORIGEM == 'SBRF')]\n",
    "        df_sbrf = pd.concat([df_sbrf, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857a334-5833-4ad4-ad43-9ac06e5c0215",
   "metadata": {},
   "source": [
    "### Concluída a etapa\n",
    "\n",
    "Este então foi o código final para concatenar os arquivos de vendas de passagens mensais baixados no DataSAS da ANAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2eca56b1-5e90-487c-ba50-28db87a32225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>EMPRESA</th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>DESTINO</th>\n",
       "      <th>TARIFA</th>\n",
       "      <th>ASSENTOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AZU</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SBAE</td>\n",
       "      <td>1007,9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AZU</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SBAE</td>\n",
       "      <td>1030,53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AZU</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SBAE</td>\n",
       "      <td>1117,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AZU</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SBAE</td>\n",
       "      <td>1157,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>AZU</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SBAE</td>\n",
       "      <td>1350,93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704222</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>TAM</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SWSI</td>\n",
       "      <td>1547,01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704223</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>TAM</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SWSI</td>\n",
       "      <td>1597,00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704224</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>TAM</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SWSI</td>\n",
       "      <td>1767,01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704225</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>TAM</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SWSI</td>\n",
       "      <td>1831,99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704226</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>TAM</td>\n",
       "      <td>SBRF</td>\n",
       "      <td>SWSI</td>\n",
       "      <td>1996,00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704227 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ANO MES EMPRESA ORIGEM DESTINO   TARIFA ASSENTOS\n",
       "0       2018   1     AZU   SBRF    SBAE   1007,9        3\n",
       "1       2018   1     AZU   SBRF    SBAE  1030,53        1\n",
       "2       2018   1     AZU   SBRF    SBAE   1117,9        1\n",
       "3       2018   1     AZU   SBRF    SBAE   1157,9        1\n",
       "4       2018   1     AZU   SBRF    SBAE  1350,93        1\n",
       "...      ...  ..     ...    ...     ...      ...      ...\n",
       "704222  2022   8     TAM   SBRF    SWSI  1547,01        1\n",
       "704223  2022   8     TAM   SBRF    SWSI  1597,00        6\n",
       "704224  2022   8     TAM   SBRF    SWSI  1767,01        1\n",
       "704225  2022   8     TAM   SBRF    SWSI  1831,99        1\n",
       "704226  2022   8     TAM   SBRF    SWSI  1996,00        4\n",
       "\n",
       "[704227 rows x 7 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sbrf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
